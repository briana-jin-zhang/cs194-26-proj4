<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Facial Keypoint Detection with Neural Networks</title>
    <link href="https://fonts.googleapis.com/css2?family=Kaushan+Script&display=swap" rel="stylesheet">
    <link href="styles/style.css" rel="stylesheet" type="text/css">
  </head>
  <body>
    <h1>Facial Keypoint Detection with Neural Networks</h1>
    <h2>Nose Tip Detection</h2>
    <p>
        First, I used a very small portion of the dataset to predict the nose tip only. The images 
        were compressed to 60x80 pixels and greyscale.
    </p>
    <h3>
        Groundtruth Keypoints
    </h3>
    <div class = 'container'>
        <div class='imgContainer'> 
            <img src="images/nosetip1.png" width=300>
        </div>

        <div class='imgContainer'> 
            <img src="images/nosetip2.png" width=300>
        </div>

        <div class='imgContainer'> 
            <img src="images/nosetip3.png" width=300>
        </div>
    </div>
    <h2>Hyperparameters and Architecture</h2>
    <p>
        I used three convolutional layers, first one of size 5, last two of size 3. The 
        number of output channels started from 1 (since the input was in greyscale) to 16,
        then to 32, then to 64. Then, I had two fully connected layers, first one with output of 64,
        second one with output of 2 since we wanted a single (x, y) point for the nose.
        
        The convolutional layers each had relu and maxpooling applied, whereas the first fully connected 
        layer had relu applied. 

        I used an Adam optimizer and tried an initial learning rate of 1e-2, 1e-3, and 1e-4, finding that 1e-3
        was the best out of the three. I ran for 15 epochs. 
    </p>
    <h3>
        MSE Loss
    </h3>
    <div class = 'container'>
        <div class='imgContainer'> 
            <img src="images/noseloss.png" width=500>
        </div>
    </div>
    <h3>
        Sampled Outputs 
    </h3>
    <div class = 'container'>
        <div class='imgContainer'> 
            <img src="images/noseout1.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/noseout2.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/noseout3.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/noseout4.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/noseout5.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/noseout6.png" width=300>
        </div>
    </div>
    <h3>
        Best and Worst Cases 
    </h3>
    <div class = 'container'>
        <div class='imgContainer'> 
            <img src="images/bestnose1.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/bestnose2.png" width=300>
        </div>
    </div>
    <div class = 'container'>
        <div class='imgContainer'> 
            <img src="images/worstnose1.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/worstnose2.png" width=300>
        </div>
    </div>
    <p>
        These images were picked based off of highest and lowest MSE loss.
        I believe the reason why it fails in the third picture might be because the mustache confused the network, 
        and the reason why it fails in the fourth picture is because her angle is a bit unusual, compared to the other straight forward faces, like the photo that performs the best.
    </p>


    <h2>Full Facial Keypoints Detection</h2>
    <p>
        Next, I repeat the process with the same training and validation data, this time with all the facial keypoints.
    </p>

    <h3>
        Groundtruth Keypoints
    </h3>
    <div class = 'container'>
        <div class='imgContainer'> 
            <img src="images/fface1.png" width=300>
        </div>

        <div class='imgContainer'> 
            <img src="images/fface2.png" width=300>
        </div>

        <div class='imgContainer'> 
            <img src="images/fface3.png" width=300>
        </div>
    </div>
    <h2>Hyperparameters and Architecture</h2>
    <p>
        I used five convolutional layers, first one of size 5, the rest of size 3. The 
        number of output channels started from 1 again to 16, and continuously doubled. 
        Then, I had two fully connected layers, first one with output of 256 this time,
        since there were more convolutional layers and following the powers of two, and
        second one with output of 58 * 2 since we wanted a single 58 points this time.
        
        Again, the convolutional layers each had relu and maxpooling applied, whereas the 
        first fully connected layer had relu applied. 

        Again I used an Adam optimizer and tried an initial learning rate of 1e-2, 1e-3, and 1e-4, 
        finding that 1e-3 was the best out of the three. I ran for 20 epochs this time since there 
        were more points, though I could've ran for longer. 
    </p>
    <h3>
        MSE Loss
    </h3>
    <div class = 'container'>
        <div class='imgContainer'> 
            <img src="images/ffaceloss.png" width=500>
        </div>
    </div>
    <h3>
        Sampled Outputs 
    </h3>
    <div class = 'container'>
        <div class='imgContainer'> 
            <img src="images/ffaceout1.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/ffaceout2.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/ffaceout3.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/ffaceout4.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/ffaceout5.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/ffaceout6.png" width=300>
        </div>
    </div>
    <h3>
        Best and Worst Cases 
    </h3>
    <div class = 'container'>
        <div class='imgContainer'> 
            <img src="images/bestfface1.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/bestfface2.png" width=300>
        </div>
    </div>
    <div class = 'container'>
        <div class='imgContainer'> 
            <img src="images/worstfface1.png" width=300>
        </div>
        <div class='imgContainer'> 
            <img src="images/worstfface2.png" width=300>
        </div>
    </div>

    <p>
        Very interestingly, the second best face was also the second worst face for nose detection.
        I suspect the reason for the failures might have been how the person is looking more downwards
        rather than straight forwards. It seems the model did well on face that were looking straight 
        on or to the side. As a reference, one of the samples shown above corresponds to the worst case 
        for nose detection, which also did not do very well.
    </p>

    <h3>
        Learned Filters 
    </h3>
    <p>
        These were the learned filters of the first layer. 
    </p>
    <div class = 'container'>
        <div class='imgContainer'>
            <img src="images/filters.png" width=800>
        </div>
    </div>

    <p>
        I was rather pleased with the result. 
        I repeat the same process to create a more feminine me. 
        This time I am less successful.
    </p>

    <div class = 'container'>
        <div class='imgContainer'>
            <img src="images/warped_feminine_me.png" width=300>
        </div>

        <div class='imgContainer'> 
            <img src="images/feminine_me.png" width=300>
        </div>
    </div>

    <p>
        I believe the reason why it did not feminize me more is because my face 
        is already fairly similar to the average female face. The only noticeable
        difference is that my eyes are slightly bigger now, but my face is 
        also wider.
    </p>

    <h2>PCA</h2>
    <p>
        Something else I decided to try was to make an eigenbasis for faces 
        based off of the FEI neutral faces. I simply did an SVD decomposition. 
        Here are the first few eigenfaces.
    </p>

    <div class = 'container'>
        <div class='imgContainer'>
            <img src="images/eface1.png" width=300>
        </div>

        <div class='imgContainer'> 
            <img src="images/eface2.png" width=300>
        </div>

        <div class='imgContainer'>
            <img src="images/eface3.png" width=300>
        </div>
    </div>

    <p>
        Lastly, one thing I did was collaborate with other students to create a 
        <a href="https://www.youtube.com/watch?v=O3vouduLS3w&feature=emb_title">video</a> 
        of our faces all morphing into each others. This was my contribution.
    </p>

    <img src="images/new_morph_seq.gif" width=400>

  </body>
</html>
